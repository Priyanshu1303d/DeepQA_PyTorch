{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/priyanshu1303d/Projects/DeepQA_PyTorch/research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/priyanshu1303d/Projects/DeepQA_PyTorch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>Leonardo-da-Vinci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the square root of 64?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the chemical symbol for gold?</td>\n",
       "      <td>Au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Which year did World War II end?</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the longest river in the world?</td>\n",
       "      <td>Nile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question             answer\n",
       "0                   What is the capital of France?              Paris\n",
       "1                  What is the capital of Germany?             Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?         Harper-Lee\n",
       "3  What is the largest planet in our solar system?            Jupiter\n",
       "4   What is the boiling point of water in Celsius?                100\n",
       "5                       Who painted the Mona Lisa?  Leonardo-da-Vinci\n",
       "6                   What is the square root of 64?                  8\n",
       "7            What is the chemical symbol for gold?                 Au\n",
       "8                 Which year did World War II end?               1945\n",
       "9          What is the longest river in the world?               Nile"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('artifacts/data_ingestion/Dataset/100_Unique_QA_Dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/priyanshu1303d/Projects/DeepQA_PyTorch'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir : Path\n",
    "    data_path : Path\n",
    "    output_dir : Path\n",
    "    vocab_file_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepQA.utils.common import read_yaml , create_directories , get_size\n",
    "from DeepQA.logging import logger\n",
    "from DeepQA.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self , config_filepath = CONFIG_FILE_PATH , params_filepath = PARAMS_FILE_PATH ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        data_transformation = DataTransformationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            vocab_file_path = config.vocab_file_path,\n",
    "            output_dir= config.output_dir\n",
    "        )\n",
    "\n",
    "        return data_transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.vocab = {\n",
    "            '<PAD>': 0,\n",
    "            '<UNK>': 1,\n",
    "            '<SOS>': 2,\n",
    "            '<EOS>': 3\n",
    "        }\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        \"\"\"Tokenizes and cleans the input text.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "        return text.split()\n",
    "\n",
    "    def build_vocab(self, dataset):\n",
    "        \"\"\"Builds a vocabulary from the dataset.\"\"\"\n",
    "        for _, row in dataset.iterrows():\n",
    "            tokens = self.tokenize(row['question']) + self.tokenize(row['answer'])\n",
    "            for token in tokens:\n",
    "                if token not in self.vocab:\n",
    "                    self.vocab[token] = len(self.vocab)\n",
    "\n",
    "    def text_to_indices(self, text: str):\n",
    "        \"\"\"Converts a single sentence into a list of indices.\"\"\"\n",
    "        return [self.vocab.get(token, self.vocab['<UNK>']) for token in self.tokenize(text)]\n",
    "\n",
    "    def df_to_indices(self, df: pd.DataFrame):\n",
    "        \"\"\"Converts an entire DataFrame's 'question' and 'answer' columns into indexed lists.\"\"\"\n",
    "        df['question_indices'] = df['question'].apply(self.text_to_indices)\n",
    "        df['answer_indices'] = df['answer'].apply(self.text_to_indices)\n",
    "        return df\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"Loads the dataset from the specified data path.\"\"\"\n",
    "        data_file = self.config.data_path\n",
    "        data_path = Path(data_file)\n",
    "        return pd.read_csv(data_path)  # Modify this if using a different format\n",
    "    \n",
    "\n",
    "    def save_dataset(self, df: pd.DataFrame, format: str = \"csv\"):\n",
    "        \"\"\"Saves the dataset to the specified output directory in the chosen format.\"\"\"\n",
    "        \n",
    "        output_path = Path(self.config.output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "        file_path = output_path / f\"preprocessed_data.{format}\"\n",
    "\n",
    "        if format == \"csv\":\n",
    "            df.to_csv(file_path, index=False)\n",
    "        elif format == \"json\":\n",
    "            df.to_json(file_path, orient=\"records\", lines=True)\n",
    "        elif format == \"pkl\":\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                pickle.dump(df, f)\n",
    "        elif format == \"pt\":\n",
    "            torch.save(df, file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported format! Choose from 'csv', 'json', 'pkl', or 'pt'.\")\n",
    "\n",
    "        print(f\"Dataset saved at: {file_path}\")\n",
    "\n",
    "        vocab_dir = Path(self.config.vocab_file_path)\n",
    "        vocab_dir.mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "        vocab_file_path = vocab_dir / \"vocab.json\"\n",
    "\n",
    "        with open(vocab_file_path, \"w\") as f:\n",
    "            json.dump(self.vocab, f, indent=4)\n",
    "\n",
    "        print(f\"Vocabulary saved at: {vocab_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-03 10:58:27,574 : INFO : common  : yaml file config/config.yaml was read succesfully]\n",
      "[2025-04-03 10:58:27,577 : INFO : common  : yaml file params.yaml was read succesfully]\n",
      "[2025-04-03 10:58:27,578 : INFO : common  : Created directory at : artifacts]\n",
      "[2025-04-03 10:58:27,579 : INFO : common  : Created directory at : artifacts/data_transformation]\n",
      "Dataset saved at: artifacts/data_transformation/Preprocessed_Data/preprocessed_data.csv\n",
      "Vocabulary saved at: artifacts/data_transformation/Vocab/vocab.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation()\n",
    "    data_transformation = DataTransformation(data_transformation_config)\n",
    "    \n",
    "    df = data_transformation.load_dataset()\n",
    "\n",
    "    # Build vocabulary\n",
    "    data_transformation.build_vocab(df)\n",
    "\n",
    "    # Convert text to indices\n",
    "    df = data_transformation.df_to_indices(df)\n",
    "\n",
    "    data_transformation.save_dataset(df)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
