{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/priyanshu1303d/Projects/DeepQA_PyTorch/research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/priyanshu1303d/Projects/DeepQA_PyTorch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir : Path\n",
    "    data_path : Path\n",
    "    output_path : Path\n",
    "    vocab_file_path : Path\n",
    "    epochs: int\n",
    "    weight_decay: float\n",
    "    learning_rate : float\n",
    "    optimizer: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepQA.constants import *\n",
    "from DeepQA.utils.common import read_yaml , create_directories , get_size\n",
    "from DeepQA.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self , config_filepath = CONFIG_FILE_PATH , params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        params = self.params.TrainingArguments\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path= config.data_path,\n",
    "            output_path= config.output_path,\n",
    "            vocab_file_path = config.vocab_file_path,\n",
    "            epochs = params.epochs,\n",
    "            weight_decay = params.weight_decay,\n",
    "            learning_rate = params.learning_rate,\n",
    "            optimizer = params.optimizer\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3 DataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataclass(Dataset):\n",
    "    def __init__(self , df , vocab):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Convert string representations of lists back to actual lists\n",
    "        numerical_question = ast.literal_eval(self.df.iloc[index]['question_indices'])\n",
    "        numerical_answer = ast.literal_eval(self.df.iloc[index]['answer_indices'])\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        question_tensor = torch.tensor(numerical_question, dtype=torch.long).unsqueeze(0)  # Add batch dimension\n",
    "        answer_tensor = torch.tensor(numerical_answer, dtype=torch.long)\n",
    "\n",
    "        return question_tensor, answer_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_final = pd.read_csv('artifacts/data_transformation/Preprocessed_Data/preprocessed_data.csv')\n",
    "import json\n",
    "\n",
    "vocab_path = \"artifacts/data_transformation/Vocab/vocab.json\"\n",
    "\n",
    "with open(vocab_path, \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "dataset = QA_Dataclass(df_final , vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self , config : ModelTrainerConfig ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        with open(config.vocab_file_path, 'r') as f:\n",
    "            vocab = json.load(f)\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "        #model creation\n",
    "        self.model = self._build_model(self.vocab_size ).to(self.device)\n",
    "\n",
    "        #model save path \n",
    "        self.output_path = Path(config.output_path)\n",
    "\n",
    "        #params init\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    def _build_model(self , vocab_size):\n",
    "        \"\"\"Builds and returns the model\"\"\"\n",
    "        return RNNModel(vocab_size, embedding_dim=50, hidden_size=64)\n",
    "\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        \"\"\"Train the model using the given dataloader.\"\"\"\n",
    "        logger.info(f\"-------------Started Training----------\")\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(self.config.epochs):\n",
    "            running_loss = 0.0  # Move inside epoch loop\n",
    "\n",
    "            for question, answer in train_loader:\n",
    "                question, answer = question.to(self.device), answer.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                output = self.model(question)\n",
    "\n",
    "                if output is None:\n",
    "                    print(\"‚ö†Ô∏è Warning: Model output is None. Skipping this batch.\")\n",
    "                    continue\n",
    "\n",
    "                # Compute loss\n",
    "                loss = self.criterion(output, answer.squeeze(1))\n",
    "\n",
    "                # Backpropagation\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()  # ‚úÖ Accumulate loss\n",
    "\n",
    "            avg_loss = running_loss / len(train_loader)  # ‚úÖ Compute average loss\n",
    "            logger.info(f\"Epoch [{epoch+1}/{self.config.epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save the model (fix below)\n",
    "        model_path = self.output_path / \"qa_rnn.pth\"\n",
    "        torch.save(self.model.state_dict(), str(model_path))\n",
    "\n",
    "        # torch.save(self.model, str(model_path))  # Saves the whole model\n",
    "\n",
    "        logger.info(f\"‚úÖ Model saved at {model_path}\")\n",
    "\n",
    "\n",
    "    def evaluate(self, val_loader):\n",
    "        \"\"\"Evaluate the model on validation data.\"\"\"\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():  # No gradients needed during evaluation\n",
    "            for question, answer in val_loader:\n",
    "                question, answer = question.to(self.device), answer.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = self.model(question)\n",
    "                loss = self.criterion(output, answer.squeeze(1))\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        print(f\"üîπ Validation Loss: {avg_loss:.4f}\")\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) \n",
    "\n",
    "        # üö® Fix: Remove the extra dimension if needed\n",
    "        if x.dim() == 4:  \n",
    "            x = x.squeeze(1)  # Remove the unnecessary 1-dim (batch_size, 1, seq_len, embedding_dim) ‚Üí (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        output, hidden = self.rnn(x)  # Pass through RNN\n",
    "        output = self.fc(output[:, -1, :])  # Take the last output for classification\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-03 18:58:56,182 : INFO : common  : yaml file config/config.yaml was read succesfully]\n",
      "[2025-04-03 18:58:56,185 : INFO : common  : yaml file params.yaml was read succesfully]\n",
      "[2025-04-03 18:58:56,186 : INFO : common  : Created directory at : artifacts]\n",
      "[2025-04-03 18:58:56,187 : INFO : common  : Created directory at : artifacts/model_trainer]\n",
      "[2025-04-03 18:58:57,634 : INFO : 12142567  : -------------Started Training----------]\n",
      "[2025-04-03 18:58:58,170 : INFO : 12142567  : Epoch [1/30], Loss: 6.0406]\n",
      "[2025-04-03 18:58:58,356 : INFO : 12142567  : Epoch [2/30], Loss: 3.7010]\n",
      "[2025-04-03 18:58:58,563 : INFO : 12142567  : Epoch [3/30], Loss: 1.7173]\n",
      "[2025-04-03 18:58:58,760 : INFO : 12142567  : Epoch [4/30], Loss: 0.8524]\n",
      "[2025-04-03 18:58:58,952 : INFO : 12142567  : Epoch [5/30], Loss: 0.4105]\n",
      "[2025-04-03 18:58:59,134 : INFO : 12142567  : Epoch [6/30], Loss: 0.4558]\n",
      "[2025-04-03 18:58:59,318 : INFO : 12142567  : Epoch [7/30], Loss: 0.3043]\n",
      "[2025-04-03 18:58:59,500 : INFO : 12142567  : Epoch [8/30], Loss: 0.0999]\n",
      "[2025-04-03 18:58:59,664 : INFO : 12142567  : Epoch [9/30], Loss: 0.1611]\n",
      "[2025-04-03 18:58:59,844 : INFO : 12142567  : Epoch [10/30], Loss: 0.1551]\n",
      "[2025-04-03 18:59:00,031 : INFO : 12142567  : Epoch [11/30], Loss: 0.0921]\n",
      "[2025-04-03 18:59:00,225 : INFO : 12142567  : Epoch [12/30], Loss: 0.0630]\n",
      "[2025-04-03 18:59:00,413 : INFO : 12142567  : Epoch [13/30], Loss: 0.0146]\n",
      "[2025-04-03 18:59:00,598 : INFO : 12142567  : Epoch [14/30], Loss: 0.0089]\n",
      "[2025-04-03 18:59:00,783 : INFO : 12142567  : Epoch [15/30], Loss: 0.0077]\n",
      "[2025-04-03 18:59:00,969 : INFO : 12142567  : Epoch [16/30], Loss: 0.0056]\n",
      "[2025-04-03 18:59:01,155 : INFO : 12142567  : Epoch [17/30], Loss: 0.0051]\n",
      "[2025-04-03 18:59:01,348 : INFO : 12142567  : Epoch [18/30], Loss: 0.0046]\n",
      "[2025-04-03 18:59:01,525 : INFO : 12142567  : Epoch [19/30], Loss: 0.0041]\n",
      "[2025-04-03 18:59:01,713 : INFO : 12142567  : Epoch [20/30], Loss: 0.0038]\n",
      "[2025-04-03 18:59:01,902 : INFO : 12142567  : Epoch [21/30], Loss: 0.0034]\n",
      "[2025-04-03 18:59:02,100 : INFO : 12142567  : Epoch [22/30], Loss: 0.0032]\n",
      "[2025-04-03 18:59:02,484 : INFO : 12142567  : Epoch [23/30], Loss: 0.0029]\n",
      "[2025-04-03 18:59:02,782 : INFO : 12142567  : Epoch [24/30], Loss: 0.0027]\n",
      "[2025-04-03 18:59:03,056 : INFO : 12142567  : Epoch [25/30], Loss: 0.0025]\n",
      "[2025-04-03 18:59:03,279 : INFO : 12142567  : Epoch [26/30], Loss: 0.0023]\n",
      "[2025-04-03 18:59:03,465 : INFO : 12142567  : Epoch [27/30], Loss: 0.0022]\n",
      "[2025-04-03 18:59:03,655 : INFO : 12142567  : Epoch [28/30], Loss: 0.0020]\n",
      "[2025-04-03 18:59:03,856 : INFO : 12142567  : Epoch [29/30], Loss: 0.0019]\n",
      "[2025-04-03 18:59:04,042 : INFO : 12142567  : Epoch [30/30], Loss: 0.0018]\n",
      "[2025-04-03 18:59:04,043 : INFO : 12142567  : ‚úÖ Model saved at artifacts/model_trainer/qa_rnn.pth]\n",
      "üîπ Validation Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    get_model_trainig_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(get_model_trainig_config)\n",
    "    train_loader = DataLoader(dataset , batch_size= 1, shuffle=True,  pin_memory=True)\n",
    "    model_trainer.train(train_loader)\n",
    "    model_trainer.evaluate(train_loader)\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
