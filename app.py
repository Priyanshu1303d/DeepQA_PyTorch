import streamlit as st
import torch
from DeepQA.config.configuration import ConfigurationManager
from DeepQA.Components.Stage_06_Model_Prediction import Predictor

# ----------------------------------------
# ğŸ”§ App config
# ----------------------------------------
st.set_page_config(page_title="DeepQA", page_icon="ğŸ“˜", layout="centered")

# ----------------------------------------
# ğŸŒ Page Navigation Sidebar
# ----------------------------------------
st.sidebar.title("ğŸ” Navigation")
page = st.sidebar.radio("Go to", ["ğŸ  Home", "ğŸ¤– Predict"])


# ================================================================
# ğŸ  HOME PAGE
# ================================================================
if page == "ğŸ  Home":
    st.title("ğŸ“˜ DeepQA - Project Overview")
    st.markdown("---")

    st.header("ğŸ“Œ Project Goal")
    st.write("""
    DeepQA is an end-to-end **Question Answering (QA)** system built using PyTorch. It processes natural language questions 
    and predicts the most likely answer word using Recurrent Neural Networks.

    This project is modular, production-ready, and supports tools like:
    - âœ… DVC for experiment tracking
    - âœ… MLflow (optional)
    - âœ… Dockerized pipeline
    - âœ… Modular configuration with YAML
    """)

    st.header("âš™ï¸ Architecture")
    st.write("""
    The pipeline includes the following stages:

    1. **Data Ingestion**: Loads raw QA pairs  
    2. **Data Validation**: Ensures schema consistency  
    3. **Data Transformation**: Tokenization, vocab building, train-test split  
    4. **Model Training**: Trains RNN on the input sequences  
    5. **Model Evaluation**: Evaluates model on test set  
    6. **Model Prediction**: Loads model and vocab to predict answers for new questions
    """)


    st.header("ğŸš€ How to Use")
    st.markdown("""
    1. Go to the **Predict** page from the sidebar  
    2. Select a model (e.g. RNN)  
    3. Enter your question  
    4. Get an instant answer!
    """)

    st.info("Model currently supports one-word answer predictions. More advanced decoding will be added later.")


# ================================================================
# ğŸ¤– PREDICT PAGE
# ================================================================
elif page == "ğŸ¤– Predict":
    st.title("ğŸ¤– DeepQA - Predict Answer")
    st.markdown("---")

    # -----------------------------
    # ğŸ”˜ Model Dropdown
    # -----------------------------
    model_options = ["RNN"]  # You can add "LSTM", "Transformer", etc. later
    selected_model = st.selectbox("Select a model", model_options)

    # -----------------------------
    # ğŸ“¦ Load model
    # -----------------------------
    if "predictor" not in st.session_state:
        st.session_state.predictor = None

    if st.button("ğŸ”„ Load Model"):
        try:
            config = ConfigurationManager()
            model_config = config.get_model_prediction_config()

            if selected_model == "RNN":
                st.session_state.predictor = Predictor(model_config)

            st.success(f"âœ… {selected_model} model loaded successfully!")

        except Exception as e:
            st.error(f"âŒ Error loading model: {str(e)}")

    # -----------------------------
    # â“ Input & Predict
    # -----------------------------
    st.subheader("Ask a question:")
    question = st.text_input("Type your question here")

    if st.button("ğŸ¯ Get Answer"):
        if not st.session_state.predictor:
            st.warning("âš ï¸ Please load a model first.")
        elif not question.strip():
            st.warning("âš ï¸ Please enter a question.")
        else:
            try:
                answer = st.session_state.predictor.predict(question)
                st.success(f"ğŸ§  Predicted Answer: **{answer}**")
            except Exception as e:
                st.error(f"âŒ Prediction failed: {str(e)}")
